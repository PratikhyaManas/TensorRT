{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:TF1120_GPU]",
      "language": "python",
      "name": "conda-env-TF1120_GPU-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Tensorflow_to_TensorRT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikhyaManas/TensorRT/blob/master/Tensorflow_to_TensorRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcqgaLv6P3ct",
        "colab_type": "text"
      },
      "source": [
        "## What is TensorRT?\n",
        "\n",
        "TensorRT is an optimization tool provided by NVIDIA that applies graph optimization and layer fusion, and finds the fastest implementation of a deep learning model. In other words, TensorRT will optimize our deep learning model so that we expect a faster inference time than the original model (before optimization), such as 5x faster or 2x faster. The bigger model we have, the bigger space for TensorRT to optimize the model. Furthermore, this TensorRT supports all NVIDIA GPU devices, such as 1080Ti, Titan XP for Desktop, and Jetson TX1, TX2 for embedded device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q-e6SBxZQEa",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMo7yGgoZM1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef0397bc-0680-44e5-b31a-17618aad9074"
      },
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFV2JIPLZlTK",
        "colab_type": "text"
      },
      "source": [
        "# Switch the current directory to the project folder of Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzL_Y3-aZZ1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "project_path = '/content/drive/My Drive/ML_Datasets/nvidia'\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZn9-Q-aMgf",
        "colab_type": "text"
      },
      "source": [
        "# Check the version of CUDA,TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v4eLCPcZ3jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6d5919d1-0dff-46e2-ca9b-4629202e9885"
      },
      "source": [
        "!nvcc --version\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1-accxPcVUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "e62af9a2-3369-4c34-80c7-c5682f426cee"
      },
      "source": [
        "!wget -O nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb https://www.dropbox.com/s/45pz13r4e8ip4bl/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb?dl=0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-06 21:44:05--  https://www.dropbox.com/s/45pz13r4e8ip4bl/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/45pz13r4e8ip4bl/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb [following]\n",
            "--2020-04-06 21:44:05--  https://www.dropbox.com/s/raw/45pz13r4e8ip4bl/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com/cd/0/inline/A1W4kdj9LrMc2dUHSCO3TmtbwUeqhmI5hmJ3ks545H-zErTQBqnop53vvFkGTMhfq2xNmQVPFFKMhjLRqhDjuBdvuRYCBx8EbF8ZMVlYALTt7A/file# [following]\n",
            "--2020-04-06 21:44:05--  https://uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com/cd/0/inline/A1W4kdj9LrMc2dUHSCO3TmtbwUeqhmI5hmJ3ks545H-zErTQBqnop53vvFkGTMhfq2xNmQVPFFKMhjLRqhDjuBdvuRYCBx8EbF8ZMVlYALTt7A/file\n",
            "Resolving uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com (uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com (uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A1XvxjR56aroz5Z1eMT-IPD7IE-MridTN-FzraPJpdXr8NrsPNKKj3CM1BAKUj90OBRSJ-JGTwGsqwbOf_PkoKnwSe88_1FfuNS7XB5apGKYnLhxwwQrFgBgI_hCSMmwjMalvrbj5KS3xDHOKHVM03LdqEHdIkrKvmlkfNVYGEIS2t-DEIPriJXJMtWxOd3UurSF2KelhF0EVV6E28C9fgQOC2spaniDJ3JvMfuzTSV6OnA0KmaEENT2wXt4L5ZSKop_gZEIqVGqkF-NBMWK0-mRfPN9paZfWl2d_YS2FhmD-7zRzZpmcVrC8zxYZ6nSRJOwrILzidKf8CUAF_8DRvV4/file [following]\n",
            "--2020-04-06 21:44:06--  https://uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com/cd/0/inline2/A1XvxjR56aroz5Z1eMT-IPD7IE-MridTN-FzraPJpdXr8NrsPNKKj3CM1BAKUj90OBRSJ-JGTwGsqwbOf_PkoKnwSe88_1FfuNS7XB5apGKYnLhxwwQrFgBgI_hCSMmwjMalvrbj5KS3xDHOKHVM03LdqEHdIkrKvmlkfNVYGEIS2t-DEIPriJXJMtWxOd3UurSF2KelhF0EVV6E28C9fgQOC2spaniDJ3JvMfuzTSV6OnA0KmaEENT2wXt4L5ZSKop_gZEIqVGqkF-NBMWK0-mRfPN9paZfWl2d_YS2FhmD-7zRzZpmcVrC8zxYZ6nSRJOwrILzidKf8CUAF_8DRvV4/file\n",
            "Reusing existing connection to uca0d5b1bbfd2b57f00039b11f88.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 843900902 (805M) [application/x-debian-package]\n",
            "Saving to: ‘nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb’\n",
            "\n",
            "nv-tensorrt-repo-ub 100%[===================>] 804.81M  10.7MB/s    in 67s     \n",
            "\n",
            "2020-04-06 21:45:14 (11.9 MB/s) - ‘nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb’ saved [843900902/843900902]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsp3LTH-dWv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "749476a8-de4a-4ead-a08d-32fd11914ee1"
      },
      "source": [
        "!dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb\n",
        "!apt-key add /var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install -y --no-install-recommends libnvinfer5=5.1.2-1+cuda10.0\n",
        "!apt-get install -y --no-install-recommends libnvinfer-dev=5.1.2-1+cuda10.0\n",
        "!apt-get install tensorrt\n",
        "!apt-get install python3-libnvinfer-dev\n",
        "!apt-get install uff-converter-tf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227_1-1_amd64.deb ...\n",
            "Unpacking nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227 (1-1) ...\n",
            "Setting up nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.1.2.2-rc-20190227 (1-1) ...\n",
            "OK\n",
            "Get:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  InRelease\n",
            "Ign:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  InRelease\n",
            "Get:2 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  Release [574 B]\n",
            "Get:2 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  Release [574 B]\n",
            "Get:3 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  Release.gpg [819 B]\n",
            "Get:3 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  Release.gpg [819 B]\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:10 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  Packages [3,347 B]\n",
            "Ign:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,810 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [873 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [873 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [38.5 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [835 kB]\n",
            "Get:20 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,367 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,170 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [54.8 kB]\n",
            "Fetched 7,292 kB in 2s (3,578 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 0 B/43.3 MB of archives.\n",
            "After this operation, 158 MB of additional disk space will be used.\n",
            "Get:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  libnvinfer5 5.1.2-1+cuda10.0 [43.3 MB]\n",
            "Selecting previously unselected package libnvinfer5.\n",
            "(Reading database ... 144589 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer5_5.1.2-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libnvinfer5 (5.1.2-1+cuda10.0) ...\n",
            "Setting up libnvinfer5 (5.1.2-1+cuda10.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 0 B/43.5 MB of archives.\n",
            "After this operation, 171 MB of additional disk space will be used.\n",
            "Get:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  libnvinfer-dev 5.1.2-1+cuda10.0 [43.5 MB]\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "(Reading database ... 144607 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer-dev_5.1.2-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (5.1.2-1+cuda10.0) ...\n",
            "Setting up libnvinfer-dev (5.1.2-1+cuda10.0) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libnvinfer-samples\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-samples tensorrt\n",
            "0 upgraded, 2 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 0 B/464 MB of archives.\n",
            "After this operation, 838 MB of additional disk space will be used.\n",
            "Get:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  libnvinfer-samples 5.1.2-1+cuda10.0 [463 MB]\n",
            "Get:2 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  tensorrt 5.1.2.2-1+cuda10.0 [1,604 kB]\n",
            "Selecting previously unselected package libnvinfer-samples.\n",
            "(Reading database ... 144636 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer-samples_5.1.2-1+cuda10.0_all.deb ...\n",
            "Unpacking libnvinfer-samples (5.1.2-1+cuda10.0) ...\n",
            "Selecting previously unselected package tensorrt.\n",
            "Preparing to unpack .../tensorrt_5.1.2.2-1+cuda10.0_amd64.deb ...\n",
            "Unpacking tensorrt (5.1.2.2-1+cuda10.0) ...\n",
            "Setting up libnvinfer-samples (5.1.2-1+cuda10.0) ...\n",
            "Setting up tensorrt (5.1.2.2-1+cuda10.0) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-cudart-10-2 cuda-cudart-dev-10-2 cuda-driver-dev-10-2 cuda-license-10-2\n",
            "  libnvinfer-dev libnvinfer-plugin-dev libnvinfer-plugin7 libnvinfer7\n",
            "  libnvonnxparsers-dev libnvonnxparsers7 libnvparsers-dev libnvparsers7\n",
            "  python3-libnvinfer\n",
            "The following packages will be REMOVED:\n",
            "  libnvinfer-samples tensorrt\n",
            "The following NEW packages will be installed:\n",
            "  cuda-cudart-10-2 cuda-cudart-dev-10-2 cuda-driver-dev-10-2 cuda-license-10-2\n",
            "  libnvinfer-plugin-dev libnvinfer-plugin7 libnvinfer7 libnvonnxparsers-dev\n",
            "  libnvonnxparsers7 libnvparsers-dev libnvparsers7 python3-libnvinfer\n",
            "  python3-libnvinfer-dev\n",
            "The following packages will be upgraded:\n",
            "  libnvinfer-dev\n",
            "1 upgraded, 13 newly installed, 2 to remove and 32 not upgraded.\n",
            "Need to get 163 MB of archives.\n",
            "After this operation, 427 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-license-10-2 10.2.89-1 [16.4 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-10-2 10.2.89-1 [111 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-10-2 10.2.89-1 [11.8 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-10-2 10.2.89-1 [491 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer7 7.0.0-1+cuda10.2 [77.2 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-dev 7.0.0-1+cuda10.2 [78.0 MB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-plugin7 7.0.0-1+cuda10.2 [2,250 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-plugin-dev 7.0.0-1+cuda10.2 [2,321 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvonnxparsers7 7.0.0-1+cuda10.2 [593 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvonnxparsers-dev 7.0.0-1+cuda10.2 [295 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvparsers7 7.0.0-1+cuda10.2 [791 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvparsers-dev 7.0.0-1+cuda10.2 [541 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  python3-libnvinfer 7.0.0-1+cuda10.2 [355 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  python3-libnvinfer-dev 7.0.0-1+cuda10.2 [3,648 B]\n",
            "Fetched 163 MB in 3s (55.6 MB/s)\n",
            "(Reading database ... 146733 files and directories currently installed.)\n",
            "Removing tensorrt (5.1.2.2-1+cuda10.0) ...\n",
            "Removing libnvinfer-samples (5.1.2-1+cuda10.0) ...\n",
            "Selecting previously unselected package cuda-license-10-2.\n",
            "(Reading database ... 144636 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-license-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-10-2.\n",
            "Preparing to unpack .../01-cuda-cudart-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-10-2.\n",
            "Preparing to unpack .../02-cuda-driver-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-10-2.\n",
            "Preparing to unpack .../03-cuda-cudart-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package libnvinfer7.\n",
            "Preparing to unpack .../04-libnvinfer7_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvinfer7 (7.0.0-1+cuda10.2) ...\n",
            "Preparing to unpack .../05-libnvinfer-dev_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (7.0.0-1+cuda10.2) over (5.1.2-1+cuda10.0) ...\n",
            "Selecting previously unselected package libnvinfer-plugin7.\n",
            "Preparing to unpack .../06-libnvinfer-plugin7_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin7 (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package libnvinfer-plugin-dev.\n",
            "Preparing to unpack .../07-libnvinfer-plugin-dev_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin-dev (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package libnvonnxparsers7.\n",
            "Preparing to unpack .../08-libnvonnxparsers7_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvonnxparsers7 (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package libnvonnxparsers-dev.\n",
            "Preparing to unpack .../09-libnvonnxparsers-dev_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvonnxparsers-dev (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package libnvparsers7.\n",
            "Preparing to unpack .../10-libnvparsers7_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvparsers7 (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package libnvparsers-dev.\n",
            "Preparing to unpack .../11-libnvparsers-dev_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libnvparsers-dev (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package python3-libnvinfer.\n",
            "Preparing to unpack .../12-python3-libnvinfer_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking python3-libnvinfer (7.0.0-1+cuda10.2) ...\n",
            "Selecting previously unselected package python3-libnvinfer-dev.\n",
            "Preparing to unpack .../13-python3-libnvinfer-dev_7.0.0-1+cuda10.2_amd64.deb ...\n",
            "Unpacking python3-libnvinfer-dev (7.0.0-1+cuda10.2) ...\n",
            "Setting up cuda-license-10-2 (10.2.89-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-10.2/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Setting up libnvinfer7 (7.0.0-1+cuda10.2) ...\n",
            "Setting up cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Setting up libnvinfer-plugin7 (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvparsers7 (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvonnxparsers7 (7.0.0-1+cuda10.2) ...\n",
            "Setting up python3-libnvinfer (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvinfer-dev (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvinfer-plugin-dev (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvparsers-dev (7.0.0-1+cuda10.2) ...\n",
            "Setting up libnvonnxparsers-dev (7.0.0-1+cuda10.2) ...\n",
            "Setting up python3-libnvinfer-dev (7.0.0-1+cuda10.2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  graphsurgeon-tf\n",
            "The following NEW packages will be installed:\n",
            "  graphsurgeon-tf uff-converter-tf\n",
            "0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 0 B/53.6 kB of archives.\n",
            "After this operation, 770 kB of additional disk space will be used.\n",
            "Get:1 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  graphsurgeon-tf 5.1.2-1+cuda10.0 [16.1 kB]\n",
            "Get:2 file:/var/nv-tensorrt-repo-cuda10.0-trt5.1.2.2-rc-20190227  uff-converter-tf 5.1.2-1+cuda10.0 [37.5 kB]\n",
            "Selecting previously unselected package graphsurgeon-tf.\n",
            "(Reading database ... 144739 files and directories currently installed.)\n",
            "Preparing to unpack .../graphsurgeon-tf_5.1.2-1+cuda10.0_amd64.deb ...\n",
            "Unpacking graphsurgeon-tf (5.1.2-1+cuda10.0) ...\n",
            "Selecting previously unselected package uff-converter-tf.\n",
            "Preparing to unpack .../uff-converter-tf_5.1.2-1+cuda10.0_amd64.deb ...\n",
            "Unpacking uff-converter-tf (5.1.2-1+cuda10.0) ...\n",
            "Setting up graphsurgeon-tf (5.1.2-1+cuda10.0) ...\n",
            "Setting up uff-converter-tf (5.1.2-1+cuda10.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-m_I5O2eXx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a2c7adef-254e-4cf0-af28-e1f3026b4445"
      },
      "source": [
        "!dpkg -l | grep TensorRT"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ii  graphsurgeon-tf                                             5.1.2-1+cuda10.0                                  amd64        GraphSurgeon for TensorRT package\n",
            "ii  libnvinfer-dev                                              7.0.0-1+cuda10.2                                  amd64        TensorRT development libraries and headers\n",
            "ii  libnvinfer-plugin-dev                                       7.0.0-1+cuda10.2                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer-plugin7                                          7.0.0-1+cuda10.2                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer5                                                 5.1.2-1+cuda10.0                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvinfer7                                                 7.0.0-1+cuda10.2                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvonnxparsers-dev                                        7.0.0-1+cuda10.2                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvonnxparsers7                                           7.0.0-1+cuda10.2                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvparsers-dev                                            7.0.0-1+cuda10.2                                  amd64        TensorRT parsers libraries\n",
            "ii  libnvparsers7                                               7.0.0-1+cuda10.2                                  amd64        TensorRT parsers libraries\n",
            "ii  python3-libnvinfer                                          7.0.0-1+cuda10.2                                  amd64        Python 3 bindings for TensorRT\n",
            "ii  python3-libnvinfer-dev                                      7.0.0-1+cuda10.2                                  amd64        Python 3 development package for TensorRT\n",
            "ii  uff-converter-tf                                            5.1.2-1+cuda10.0                                  amd64        UFF converter for TensorRT package\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T7h9KhcSyzH",
        "colab_type": "text"
      },
      "source": [
        "# Importing the Required Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WkYWnYaP3cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the needed libraries\n",
        "import tensorflow.contrib.tensorrt as trt\n",
        "from tensorflow.python.platform import gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E-tYH4OP3cv",
        "colab_type": "text"
      },
      "source": [
        "# Convert Tensorflow Model to Frozen Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78Ca_q0nRgTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "26338bec-083d-4482-f9da-e8a95e0611c6"
      },
      "source": [
        "# has to be use this setting to make a session for TensorRT optimization\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.50))) as sess:\n",
        "    # import the meta graph of the tensorflow model\n",
        "    #saver = tf.train.import_meta_graph(\"./model/tensorflow/big/model1.meta\")\n",
        "    saver = tf.train.import_meta_graph(\"/content/drive/My Drive/ML_Datasets/nvidia/model/tensorflow/small/model_small.meta\")\n",
        "    # then, restore the weights to the meta graph\n",
        "    #saver.restore(sess, \"./model/tensorflow/big/model1\")\n",
        "    saver.restore(sess, \"/content/drive/My Drive/ML_Datasets/nvidia/model/tensorflow/small/model_small\")\n",
        "    \n",
        "    # specify which tensor output you want to obtain \n",
        "    # (correspond to prediction result)\n",
        "    your_outputs = [\"output_tensor/Softmax\"]\n",
        "    \n",
        "    # convert to frozen model\n",
        "    frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
        "        sess, # session\n",
        "        tf.get_default_graph().as_graph_def(),# graph+weight from the session\n",
        "        output_node_names=your_outputs)\n",
        "    #write the TensorRT model to be used later for inference\n",
        "    with gfile.FastGFile(\"/content/drive/My Drive/ML_Datasets/nvidia/model/frozen_model.pb\", 'wb') as f:\n",
        "        f.write(frozen_graph.SerializeToString())\n",
        "    print(\"Frozen model is successfully stored!\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/ML_Datasets/nvidia/model/tensorflow/small/model_small\n",
            "INFO:tensorflow:Froze 10 variables.\n",
            "INFO:tensorflow:Converted 10 variables to const ops.\n",
            "Frozen model is successfully stored!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnphXIxrP3cz",
        "colab_type": "text"
      },
      "source": [
        "# Optimize the frozen model to TensorRT graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLzjZudPP3cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "221e7b82-0a69-4b59-c6b1-14e005a7c1b7"
      },
      "source": [
        "# convert (optimize) frozen model to TensorRT model\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,# frozen model\n",
        "    outputs=your_outputs,\n",
        "    max_batch_size=2,# specify your max batch size\n",
        "    max_workspace_size_bytes=2*(10**9),# specify the max workspace\n",
        "    precision_mode=\"FP32\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\"\n",
        "\n",
        "#write the TensorRT model to be used later for inference\n",
        "with gfile.FastGFile(\"/content/drive/My Drive/ML_Datasets/nvidia/model/TensorRT_model.pb\", 'wb') as f:\n",
        "    f.write(trt_graph.SerializeToString())\n",
        "print(\"TensorRT model is successfully stored!\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
            "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
            "INFO:tensorflow:Running against TensorRT version 0.0.0\n",
            "TensorRT model is successfully stored!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Bn4o_vP3c2",
        "colab_type": "text"
      },
      "source": [
        "# Count how many nodes/operations before and after optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxrfSiNP3c2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e1a87dc7-dd22-4776-af32-0727db52bec3"
      },
      "source": [
        "# check how many ops of the original frozen model\n",
        "all_nodes = len([1 for n in frozen_graph.node])\n",
        "print(\"numb. of all_nodes in frozen graph:\", all_nodes)\n",
        "\n",
        "# check how many ops that is converted to TensorRT engine\n",
        "trt_engine_nodes = len([1 for n in trt_graph.node if str(n.op) == 'TRTEngineOp'])\n",
        "print(\"numb. of trt_engine_nodes in TensorRT graph:\", trt_engine_nodes)\n",
        "all_nodes = len([1 for n in trt_graph.node])\n",
        "print(\"numb. of all_nodes in TensorRT graph:\", all_nodes)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numb. of all_nodes in frozen graph: 46\n",
            "numb. of trt_engine_nodes in TensorRT graph: 0\n",
            "numb. of all_nodes in TensorRT graph: 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHLIHxnYP3c5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee4d3271-f33b-4724-c89f-374ede001de0"
      },
      "source": [
        "\n",
        "!TensorRT --version"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: TensorRT: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwkAnZ2XqLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}